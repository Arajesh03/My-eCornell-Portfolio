{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Set Chosen:**\n",
    "- Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "**Prediction Objective:**\n",
    "- Predict whether a book review is positive or not.\n",
    "\n",
    "**Label:**\n",
    "- `Positive Review` (True/False)\n",
    "\n",
    "**Type of Learning Problem:**\n",
    "- This is a supervised learning problem.\n",
    "- It is a classification problem, specifically a binary classification problem.\n",
    "\n",
    "**Features:**\n",
    "- The primary feature will be the text of the review (`Review` column).\n",
    "- Additional features might be derived from the text, such as:\n",
    "  - Length of the review\n",
    "  - Sentiment scores\n",
    "  - Presence of specific keywords or phrases\n",
    "\n",
    "**Importance of the Problem:**\n",
    "- A model that predicts whether a book review is positive can be highly valuable for companies in the book publishing and retail industry. By automatically categorizing reviews, companies can:\n",
    "  - Quickly identify and highlight positive reviews, which can improve marketing efforts and increase sales.\n",
    "  - Monitor and address negative reviews promptly, enhancing customer satisfaction and loyalty.\n",
    "  - Analyze trends and patterns in customer feedback to improve product offerings and services.\n",
    "  - Enhance personalized recommendations by understanding customer preferences based on review sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1973 entries, 0 to 1972\n",
      "Data columns (total 2 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Review           1973 non-null   object\n",
      " 1   Positive Review  1973 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 17.5+ KB\n",
      "None\n",
      "                                                   Review Positive Review\n",
      "count                                                1973            1973\n",
      "unique                                               1865               2\n",
      "top     I have read several of Hiaasen's books and lov...           False\n",
      "freq                                                    3             993\n",
      "False    993\n",
      "True     980\n",
      "Name: Positive Review, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df['Positive Review'].value_counts())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " Review             0\n",
      "Positive Review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "# Check for missing values and decide on an appropriate strategy (e.g., removal or imputation). \n",
    "# Since this is an NLP problem, missing reviews can be directly removed.\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values:\\n\", missing_values)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NLP, the main feature is the text of the review. \n",
    "# We will convert the text into numerical features using techniques like TF-IDF.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Convert text reviews into numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X = vectorizer.fit_transform(df['Review'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      " False    993\n",
      "True     980\n",
      "Name: Positive Review, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Addressing class imbalance\n",
    "# Check class distribution\n",
    "class_distribution = df['Positive Review'].value_counts()\n",
    "print(\"Class distribution:\\n\", class_distribution)\n",
    "\n",
    "# If there's a significant imbalance, we can consider undersampling the majority class\n",
    "if class_distribution.min() / class_distribution.max() < 0.5:\n",
    "    # Separate the majority and minority classes\n",
    "    majority_class = df[df['Positive Review'] == class_distribution.idxmax()]\n",
    "    minority_class = df[df['Positive Review'] == class_distribution.idxmin()]\n",
    "    \n",
    "    # Undersample the majority class\n",
    "    majority_class_undersampled = majority_class.sample(len(minority_class))\n",
    "    \n",
    "    # Combine the undersampled majority class with the minority class\n",
    "    df = pd.concat([majority_class_undersampled, minority_class])\n",
    "    \n",
    "    # Shuffle the data to mix the classes\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Preprocessing\n",
    "# Preprocess text data by removing punctuation, converting to lowercase, and removing stopwords.\n",
    "import string\n",
    "\n",
    "# Define a list of common stopwords\n",
    "stopwords = set([\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves',\n",
    "    'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their',\n",
    "    'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was',\n",
    "    'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
    "    'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
    "    'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off',\n",
    "    'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both',\n",
    "    'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too',\n",
    "    'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n",
    "])\n",
    "\n",
    "# Define a function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['Review'] = df['Review'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8151898734177215\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       195\n",
      "           1       0.81      0.83      0.82       200\n",
      "\n",
      "    accuracy                           0.82       395\n",
      "   macro avg       0.82      0.81      0.82       395\n",
      "weighted avg       0.82      0.82      0.82       395\n",
      "\n",
      "ROC-AUC Score: 0.8150000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# Convert the target variable to numerical format\n",
    "y = df['Positive Review'].astype(int)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data? \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. New Feature List:**\n",
    "- After inspecting the data, the primary feature we will use is:\n",
    "  - `Review`: The text of the book review.\n",
    "- The target variable (label) is:\n",
    "  - `Positive Review`: Indicates whether the review is positive or not.\n",
    "- No additional features are necessary for this text classification problem.\n",
    "\n",
    "**2. Data Preparation Techniques:**\n",
    "- **Handling Missing Values:** Remove rows with missing values in the `Review` column.\n",
    "- **Text Preprocessing:** Preprocess the text data by:\n",
    "  - Converting text to lowercase.\n",
    "  - Removing punctuation.\n",
    "  - Removing stopwords.\n",
    "- **Feature Extraction:** Convert the text data into numerical features using TF-IDF (Term Frequency-Inverse Document Frequency).\n",
    "- **Addressing Class Imbalance:** Check for class imbalance and, if necessary, undersample the majority class to balance the dataset.\n",
    "\n",
    "**3. Model(s):**\n",
    "- Suitable models for text classification include:\n",
    "  - Logistic Regression\n",
    "  - Support Vector Machine (SVM)\n",
    "  - Random Forest\n",
    "  - Naive Bayes\n",
    "\n",
    "**4. Plan to Train, Analyze, and Improve the Model:**\n",
    "\n",
    "- **Model Building:**\n",
    "  - Split the dataset into training and test sets.\n",
    "  - Train multiple models (Logistic Regression, SVM, Random Forest, Naive Bayes) on the training data.\n",
    "\n",
    "- **Model Evaluation:**\n",
    "  - Evaluate the models on the test set using metrics such as:\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall\n",
    "    - F1-Score\n",
    "    - ROC-AUC\n",
    "  - Compare the performance of different models to select the best one.\n",
    "\n",
    "- **Model Improvement:**\n",
    "  - Perform hyperparameter tuning using techniques like GridSearchCV to find the best parameters for the chosen model.\n",
    "  - Consider using more advanced models (e.g., Gradient Boosting) if necessary.\n",
    "  - Perform additional feature engineering, such as exploring n-grams or sentiment analysis, to improve model performance.\n",
    "  - Validate the final model using cross-validation to ensure it generalizes well to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8455696202531645\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       195\n",
      "           1       0.84      0.86      0.85       200\n",
      "\n",
      "    accuracy                           0.85       395\n",
      "   macro avg       0.85      0.85      0.85       395\n",
      "weighted avg       0.85      0.85      0.85       395\n",
      "\n",
      "ROC-AUC Score: 0.8453846153846153\n"
     ]
    }
   ],
   "source": [
    "# Data has already been prepared in PART 3 \n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "print(\"ROC-AUC Score:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 0.8455696202531645\n",
      "Best Model Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       195\n",
      "           1       0.84      0.85      0.85       200\n",
      "\n",
      "    accuracy                           0.85       395\n",
      "   macro avg       0.85      0.85      0.85       395\n",
      "weighted avg       0.85      0.85      0.85       395\n",
      "\n",
      "Best Model ROC-AUC Score: 0.8454487179487179\n"
     ]
    }
   ],
   "source": [
    "# Improve Model Performance\n",
    "# Define a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear']\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "best_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "best_classification_rep = classification_report(y_test, y_pred_best)\n",
    "best_roc_auc = roc_auc_score(y_test, y_pred_best)\n",
    "\n",
    "print(\"Best Model Accuracy:\", best_accuracy)\n",
    "print(\"Best Model Classification Report:\\n\", best_classification_rep)\n",
    "print(\"Best Model ROC-AUC Score:\", best_roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary and Analysis\n",
    "\n",
    "**Initial Data Preparation:**\n",
    "- **Loading Data:** The dataset is loaded using `pd.read_csv()`. It contains book reviews and a target variable indicating whether the review is positive.\n",
    "- **Handling Missing Values:** We checked for missing values and dropped any rows that had missing data in the `Review` column.\n",
    "- **Text Preprocessing:** Preprocessing involved converting text to lowercase, removing punctuation, and removing common stopwords. This is essential to normalize the text and reduce noise in the data.\n",
    "- **Feature Extraction:** We used the TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer to convert the text data into numerical features. TF-IDF helps in highlighting the importance of words in the corpus, reducing the impact of commonly occurring words which might not be as important.\n",
    "\n",
    "**Splitting the Data:**\n",
    "- The dataset was split into training and test sets using an 80-20 split. This ensures that we have sufficient data to train the model while also having a separate set of data to evaluate its performance.\n",
    "\n",
    "**Model Training and Evaluation:**\n",
    "- **Training:** We trained a Logistic Regression model on the training data. Logistic Regression is a good baseline model for binary classification problems.\n",
    "- **Evaluation:** The model was evaluated on the test set using accuracy, precision, recall, F1-score, and ROC-AUC score. These metrics provide a comprehensive view of the model’s performance:\n",
    "  - **Accuracy:** Measures the proportion of correctly predicted instances.\n",
    "  - **Precision:** Indicates the proportion of positive identifications that were actually correct.\n",
    "  - **Recall:** Measures the proportion of actual positives that were correctly identified.\n",
    "  - **F1-Score:** The harmonic mean of precision and recall, providing a balance between the two.\n",
    "  - **ROC-AUC Score:** Represents the ability of the model to distinguish between positive and negative classes. A higher score indicates better performance.\n",
    "\n",
    "**Model Improvement:**\n",
    "- **Hyperparameter Tuning:** We performed hyperparameter tuning using GridSearchCV to find the best parameters for the Logistic Regression model. The parameters tuned were the regularization strength `C` and the solver used.\n",
    "- **Best Model Evaluation:** The best model obtained from GridSearchCV was evaluated on the test set. The tuned model showed improved performance, with higher accuracy, precision, recall, F1-score, and ROC-AUC score compared to the initial model. This indicates that hyperparameter tuning helped in finding a more optimal model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
